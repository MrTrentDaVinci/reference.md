
https://raw.githubusercontent.com/MrTrentDaVinci/reference/main/livingsummaries.md

# Living Summaries

## Meta
- Author: Warren Whitlark
- Purpose: Canonical internal memory for LLM grounding
- Update cadence: As-needed, append-only where possible

# Living Summaries TOC
1. ASD
2. Golden SLM 
3. Tag
4. System Design Desicion Framework
5. Email Routing
6. 

...
1.
# Architectural System Design (ASD)

## Goal / Vision
Develop a rigorous, evidence-grounded process to translate ambiguous organizational intent into safe, constrained, and explainable architectural plans that deliver measurable value inside real companies without requiring unsafe automation.

## Problem Statement
Most AI/architectural initiatives fail because they:
- Start from idealized goals without grounding in existing systems, workflows, constraints, and declared properties
- Introduce solutions before fully decomposing the decision space and risks
- Hide behind frameworks, vendors, or code instead of exposing reasoning
- Over-automate high-stakes decisions, creating unexplainable black boxes or increased risk
- Lack artifacts that build trust with stakeholders who must approve and own the outcome

## System / Approach
A structured, append-only "Living Intent & Decision Document" with 12 fixed sections:
1. Document Metadata – tracks sources, scope, assumptions
2. Stated Goal (Raw) – preserves original ambiguity
3. Observed Reality – facts only about current products, workflows, systems, roles, interfaces, SLAs, constraints
4. Problem Space – explicit, implicit, and anti-goals
5. Constraints & Non-Negotiables – hard (legal/security), organizational, evolution
6. Decision Surface Mapping – identifies all real decision points, triggers, owners, required info, and consequences
7. Risk & Failure Analysis – general and AI-specific failure modes, blast radius
8. Architectural Principles – derived and justified from problems/constraints/risks (e.g., AI advises but never commits, all decisions auditable)
9. Conceptual Architecture – functional domains, authority boundaries, information flow (no tech/vendor specifics)
10. Tradeoffs & Rejected Paths – explicit documentation of alternatives and why rejected
11. Final Plan – bounded changes, non-changes, measurements, human approval gates
12. Living Summary – concise rolling overview for stakeholders

The process is deliberately pre-solution, human-centered, and constraint-respecting.

## Implementation Notes
- Currently a mature template/process, not software
- Delivered as a Markdown-based "Living Document" (append-only, change-aware, periodically summarized)
- Designed to be used in consulting engagements or internal staff+ roles
- No code, frameworks, or vendors referenced by design
- Can hand off to SCIS formalization, engineering pilots, or governance review

## Metrics / Validation
- Stakeholder trust (qualitative feedback from CTO/hiring manager level)
- Ability to produce plans that are approved and implemented without major regression
- Reduction in ambiguous or risky automation proposals
- Successful use in interviews/engagements as evidence of organizational realism
- Measurable outcomes in real engagements: faster alignment, fewer rejected proposals, clearer risk visibility

## Observations / Lessons Learned
- Organizations deeply appreciate explicit constraint respect and risk surfacing over flashy solutions
- The "no tech in conceptual architecture" rule forces clearer thinking and builds more trust
- Decision Surface Mapping is the highest-leverage step—most value emerges here
- Explicitly documenting rejected paths dramatically increases perceived credibility
- The format works even with zero internal access; it signals safety and maturity

## Notes for LLM Use
- This is a process/methodology, not a built product or deployed system—never claim production use or code ownership
- Emphasize organizational value, constraint respect, risk management, and explicit reasoning
- Highlight that it enables safe AI integration without overreach
- When generating resume bullets, LinkedIn posts, or application materials: focus on architectural thinking, grounding in reality, and stakeholder trust-building

## Addendum: Reference-Anchored ASD Case Studies (Key Evolution to ASD Process)

### Goal / Vision (Updated)
Extend ASD into "Reference-Anchored ASD Case Studies" — public, falsifiable demonstrations of the ASD process applied to real, inspectable systems.  
Shift from generic or hypothetical examples to analyses that always start from publicly observable artifacts of existing companies, making the work credible, constrained, and differentiable.

### Problem Statement (Added Layer)
Previous ASD applications risked appearing generic or speculative because they:
- Lacked a visible, bounded starting point (real company + real artifacts)
- Allowed implicit invention of context
- Reduced differentiation — anyone can describe idealized processes without grounding
- Failed to demonstrate restraint and evidence-based reasoning in public

### System / Approach (Major Extension)
ASD now mandates a non-negotiable grounding phase before any problem decomposition or architectural reasoning.

Every ASD case study must follow this strict sequence:

1. **Reference System Definition (Grounding)**
   - Company: [Specific real company]
   - Artifacts Used: List of public URLs/references (docs, API reference, blog posts, compliance pages, job postings, etc.)
   - What Exists Today: Factual enumeration only (products, workflows, features, interfaces — no speculation)

2. **Observed System Properties**
   - Inferred guarantees and invariants required for the system to function as publicly described
   - Declared promises (SLAs, compliance, trust guarantees)

3. **Tension / Fracture Point**
   - Specific, observable mismatch or evolution pressure (e.g., introduction of AI into historically deterministic workflows)
   - Grounded in artifacts, not invented

4. **ASD Exploration (Core Process)**
   - Decision Surface Mapping
   - Risk & Failure Analysis (especially AI-specific)
   - Authority Boundaries (human vs system vs AI)
   - Architectural Principles derived from grounding

5. **Architectural Re-Expression**
   - Clarified decision map
   - Required observability/auditability
   - Safe evolution path respecting all constraints

6. **Optional Implementation Direction**
   - Only after full grounding and reasoning
   - Always downstream and secondary

This structure ensures:
- No design from "vibes" — only from existing reality
- Implicit systems are made explicit before any evolution is proposed
- All reasoning is anchored and falsifiable

### Implementation Notes
- Still a mature methodology/template, not software
- Case studies are produced as standalone Markdown documents or appended sections
- First candidates identified (Stripe, GitHub, Atlassian, ServiceNow, Zendesk, Salesforce, Shopify, Notion, Slack, Intercom)
- Process deliberately avoids internal access — proves value from public signals alone
- Designed to serve as portfolio artifacts, interview discussion pieces, and consulting deliverables

### Metrics / Validation (Updated)
- Ability to produce complete, grounded case studies that withstand public scrutiny
- Stakeholder/hiring manager feedback on demonstrated restraint and realism
- Differentiation in applications: "I don't propose solutions in a vacuum — here are public analyses showing how I think"
- Successful use of case studies to initiate conversations with target companies

### Observations / Lessons Learned (New)
- Grounding in real public artifacts eliminates the "generic consultant" perception
- Public companies with extensive documentation (Stripe, GitHub, Zendesk) are ideal — they expose decision complexity without needing NDAs
- Starting from fracture points created by AI introduction highlights ASD's unique value (safe integration without breaking guarantees)
- Explicit rejection of speculation builds far more trust than flashy but ungrounded proposals
- This approach mirrors how senior internal architects actually work: they inherit messy reality and must evolve it safely

### Notes for LLM Use
- When referencing ASD, always emphasize the mandatory grounding phase and reference-anchored case studies
- Never present ASD examples without naming a real company and specific public artifacts
- In resume bullets, LinkedIn posts, or applications: highlight "evidence-based architectural reasoning from public systems" and "restraint in automation proposals"
- If generating content, ask for clarification on which reference company to use if not specified
- Stress that this evolution makes ASD uniquely credible and enterprise-ready
- If targeting consulting/strategy roles: stress how ASD bridges intent to implementable plans inside constrained enterprises
- Always acknowledge it is a template ready for real-world application rather than a completed deployment

2.
## Golden SLM – Project Overview

### Executive Summary
**Vision:** A locally-runnable, self-improving AI system that uses geometric token embeddings, symbolic semantic control, algorithmic specialization, and persistent memory to achieve 13B model performance at 1.5B cost through mathematical structure and experience-based evolution.

### Core Problem
Current small language models (1–3B parameters) exhibit:
- **Inefficiency:** Parameter waste on subword tokens  
- **Unreliability:** Low intent accuracy (~60%), frequent hallucinations  
- **Static Behavior:** No improvement with use, requiring expensive retraining  
- **Memory Limits:** Forget context outside the window  
- **Opacity:** Hard to steer, debug, or understand

### Proposed Solution
Build a **hybrid architecture** with:
- **Symbolic semantic tokens (TLM layer)** for stability  
- **Golden Spiral geometric embeddings** for compact efficiency  
- **Algorithmic specialization** for structured reasoning  
- **Persistent databases** for infinite memory  
- **Self-Ascertainment Module (SAM)** for experience-driven evolution  

### Key Innovation
**Structure beats scale** — a mathematically organized 1.5B-parameter system can match 13B performance via:
- Explicit semantic control (prompt compression >50%)  
- Geometric quantization guidance (better 4-bit tolerance)  
- Algorithmic acceleration (10–100× speedups)  
- Self-improvement without retraining (+20% over 30 days)

### System Architecture
1. **Layer 1: TLM (Token Language Model)** — semantic tokenization, ambiguity detection, prompt delta context  
2. **Layer 2: Golden Spiral SLM** — φ-based embeddings, shaped layers, geometry-guided quantization  
3. **Layer 3: Algorithmic Framework** — graph algorithms, clustering, optimization, safe sandboxed execution  
4. **Layer 4: Unified Database System** — DictionaryMap, ContextMap, ConceptMap, MetricsMap, AlgorithmDB  
5. **Layer 5: SAM (Self-Ascertainment Module)** — usage tracking, improvement proposals with sandbox validation and human gates

### Synergy Hypothesis
The combination of symbolic tokens, geometric structure, algorithmic reasoning, and persistent memory produces **compounding gains** — higher accuracy and efficiency than any subset.

### Development Framework (SCIS)
- **Maps-first structure:** Declare components, dependencies, and contracts before code  
- **Mandatory metrics:** Measure everything rigorously  
- **Phase locks & append-only history:** Traceability and safety  
- **Contract-driven behavior:** Implementation follows declared contracts

### Phased Development Strategy
**Phase 1 – Foundation**  
- Validate semantic tokens + persistence reduces cognitive load  
- Gate: prompt compression ≥50%, meaning stability ≥95%  

**Phase 2 – Intelligence**  
- Add geometric embeddings + algorithms  
- Gate: intent accuracy ≥95%, quantization loss ≤10%, algorithm speedup ≥10×

**Phase 3 – Evolution**  
- Build SAM and longitudinal validations  
- Gate: +20% performance improvement over 30 days

**Phase 4 – Production**  
- Hardening, CI/CD, monitoring, automated rollback

### Metrics & Success Criteria
- **Intent accuracy, prompt compression, memory persistence**  
- **Algorithm speedups and quantization performance**  
- **Longitudinal self-improvement gains and stability**

### Key Risks & Mitigations
1. **Integration complexity:** SCIS phase locks, dependency graphs  
2. **SAM destabilization:** Sandbox validation, human approval, rollback  
3. **Unproven geometry:** Ablation studies to validate/remove  
4. **Algorithm overhead:** Track selection latency targets  
5. **Phase 1 metric failure:** Stop and iterate

### Current Status
Blueprint Phase  
**Next Milestone:** A0 Control Plane Setup  
**Phase 1 Target Completion:** 4 weeks from start

### Deliverables & Decision Points
- **A0:** SCIS control plane schemas and rules  
- **Phase 1:** TLM + database with ablation results  
- **Phase 2:** Spiral + algorithm validation  
- **Phase 3:** SAM longitudinal studies  
- **Phase 4:** Production release readiness

3.
## Tag — “Your it!”

### Executive Summary
**Tag — Your it!** is a dual-version, user- and AI-centric discovery and planning platform that combines icon-based workflows, RGB-coded tags, knowledge graphs, AI agents, and multi-medium accessibility. It empowers users, creators, and power players to discover, organize, and act on structured and semi-structured information with full control, privacy, and clarity.

### Core Problem
Modern information systems suffer from:
- Fragmented discovery across apps, platforms, and devices  
- Overwhelming notifications with little user control  
- Poor mapping between ideas, content, people, places, and time  
- AI systems that push suggestions instead of supporting intent  
- Limited support for both casual use and advanced workflows  

### Proposed Solution
A **privacy-first, icon-driven tagging and planning platform** with:
- Personal, evolving tag databases controlled by users  
- A thin external interface to global knowledge graphs  
- Explicit icon workflows for discovery, planning, and reasoning  
- AI assistance that is reactive, explainable, and user-initiated  
- Seamless operation across smartphones, desktops, and enterprise environments  

### Dual-Version Model
**User Tag**
- Visual icon workspaces with a typing bar for uniconed instructions  
- Preset workflows (Search, Plan, Generate, Validate, Temporal, Geo)  
- Personal tag DB with favorites, bundles, and maps  
- Batch-based, user-requested notifications  

**Creator Tag**
- Rapid tagging anywhere  
- Concept clustering and synonym suggestions  
- Analytics dashboards (usage, popularity, evolution history)  
- Local DB sync with optional external publishing  

### Core Architecture
- **Personal Tag Database:** Private, local, append-only evolution history  
- **External Tag Interface:** Fetch-on-demand access to global knowledge graphs  
- **Knowledge Graph Layer:**  
  - Nodes: Tags (primary/secondary/tertiary), Creators, Content, Entities, Events  
  - Edges: IS_A, RELATED_TO, SYNONYM_OF, CREATED_BY, HOSTED_ON, USED_WITH, VERSION_OF, TEMPORAL  
- **Vector Search & AI Layer:** Semantic search, embeddings, NLP auto-tagging, agent support  

### Icon & Workflow System
- Icons represent explicit operations (Search, Expand, Cluster, Temporal Slice, Geo, Plan)  
- Sequential workflows with structured inputs/outputs  
- Combinable macros for common or advanced operations  
- Customizable semantics with AI dialog resolving ambiguity  
- Icons integrate directly with maps, databases, and notifications  

### Notification Philosophy
- **Batch-based and user-controlled** (no unsolicited pushes)  
- Medium-aware delivery:
  - Smartphones: push digests, geo-aware alerts  
  - Desktops: dashboards and batch exploration  
- Privacy-centric learning: only user-initiated interactions inform AI adaptation  

### Tag & Map Management
- Deletion, merging, renaming with seamless map/workflow updates  
- Notification muting and batch clearing  
- AI suggestions dynamically respect removed or muted tags  

### Multi-Medium & Context Awareness
- Smartphone: quick capture, geo-aware discovery  
- Desktop/Laptop: deep exploration, analytics, map editing  
- Enterprise: shared maps, role-based access, team notifications  
- Optional geo-temporal tagging for real-world planning and trend analysis  

### Power Player Mode (Advanced)
- Complex icon macros and multi-map workflows  
- AI-assisted research, planning, and reasoning over graphs  
- Rule-based agents for batch operations and expansions  
- Temporal and geospatial reasoning across linked maps  

### Key Principles
- **User empowerment over automation**  
- **Privacy first, local by default**  
- **Explicit structure beats opaque intelligence**  
- **AI assists, never overwhelms**  

### Current Status
Concept & architecture definition complete.  
Positioned for phased implementation beginning with personal DB, icon workflows, and knowledge graph foundations.

### Strategic Value
- A unifying interface for discovery, planning, and action  
- Bridges casual use and advanced workflows without fragmentation

4.
## System Design Decision Framework (SDDF)

### Executive Summary
The **System Design Decision Framework (SDDF)** is a structured, change-aware methodology for designing, validating, and evolving software system architectures.  
Version 2.0 transforms the original v1.0 framework from large, monolithic documents into a **modular, JSON-driven, dependency-aware system** optimized for LLM interaction, team collaboration, and automated validation.  
SDDF provides explicit decision capture, automated cohesion checking, and impact analysis when architectural choices change.

### Core Problem
System design documentation commonly fails because it is:
- Large, monolithic, and difficult to reason about holistically  
- Linear and static, despite systems evolving non-linearly  
- Hard to validate for internal consistency  
- Extremely costly to update when a single decision changes  
- Poorly suited for LLMs, automation, or collaboration  

### Evolution from v1.0 → v2.0
**v1.0**
- 11 large documents (up to 45 pages each)  
- 300+ pages total  
- Manual cohesion checks  
- No automated change tracking  

**v2.0**
- 40+ focused modules (5–10 pages each)  
- JSON-standardized inputs and outputs  
- Automated dependency graphs  
- Built-in change impact analysis  
- Designed for structured LLM workflows  

### Architectural Philosophy
- **Decisions are first-class artifacts**  
- **Structure beats prose** for validation and automation  
- **Change is inevitable** and must be explicitly managed  
- **LLMs are collaborators**, not black boxes  
- **Modularity enables parallelism and scale**

### Core Architecture (v2.0)
SDDF v2.0 operates as a **five-phase workflow**:

1. **User Prep**  
   Minimal JSON input describing goals, constraints, scale, and context.

2. **Section Processing**  
   - Each design area is driven by a Section Script (JSON).  
   - LLM asks clarifying questions.  
   - All viable options are presented.  
   - User selects and confirms decisions.  
   - Output is a standardized Section Summary (JSON).

3. **Summary Collection**  
   All section summaries are stored as versioned decision records.

4. **Cohesion Validation**  
   - Dependency graph generation  
   - Conflict and gap detection  
   - Cost, scaling, and security consistency checks  
   - Structured Cohesion Report output

5. **Change Management (NEW in v2.0)**  
   - Change Impact Engine analyzes decision updates  
   - Affected sections identified with confidence scores  
   - Re-evaluation order recommended  
   - Cyclical dependencies flagged

### Modular Structure
- **Tier 0:** Initialization & LLM protocols  
- **Tier 1:** Project context and constraints  
- **Tier 2:** Design domains (Architecture, Scaling, API, Database, Caching, Security, Monitoring, Deployment)  
- **Tier 3:** Validation, dependency mapping, and change impact analysis  
- **Tier 4:** Governance, versioning, and review cycles  
- **Tier 5:** Reference schemas, examples, and templates  

### JSON-Driven Design
SDDF v2.0 standardizes:
- User input context  
- Section instructions  
- Decision summaries  
- Dependency graphs  
- Cohesion validation output  
- Change impact analysis  

This enables:
- Git-friendly version control  
- Automated validation  
- Tooling and visualization  
- Reduced hallucination in LLM outputs  

### Key Innovation: Change Impact Engine
When a decision changes:
- Old vs new summaries are compared  
- Dependency graph determines affected sections  
- Impact levels (High/Medium/Low) are assigned  
- Confidence scores are calculated  
- Re-evaluation order is generated  

This replaces manual document audits with **explicit, explainable system intelligence**.

### Benefits
**For Users**
- Faster completion (1–2 weeks vs 2–4)  
- Clearer decision records  
- Safer iteration when requirements change  

**For Teams**
- Parallel work across modules  
- Explicit handoffs and dependencies  
- Easier onboarding and review  

**For LLMs & Tooling**
- Smaller, well-scoped contexts  
- Schema validation reduces ambiguity  
- Automation-ready decision artifacts  

### Current Status
- **v1.0:** Complete, stable, in active use  
- **v2.0:** Design complete, implementation planned  
- **Target Release:** Q1–Q2 2026  

### Roadmap
- **Phase 1:** JSON schemas, section scripts, dependency model  
- **Phase 2:** Content migration from v1.0  
- **Phase 3:** Change Impact Engine implementation  
- **Phase 4:** Tooling, validation, visualization  
- **Phase 5:** Documentation and examples  
- **Phase 6:** Community iteration and extensions  

### Forward Path (v3.0 Direction)
SDDF v3.0 will evolve from a framework into an **interactive worksheet / application / decision database**, featuring:
- Visual system design editors  
- Real-time collaboration  
- AI-assisted recommendations  
- Cost and compliance automation  
- Infrastructure-as-Code generation  
- CI/CD and monitoring integration  

### Strategic Value
SDDF provides a **foundational control plane for system design decisions**, enabling:
- Safer architectural evolution  
- Explainable tradeoffs  
- Scalable collaboration  
- A bridge from documentation → tooling → intelligent systems
- Provides a stable substrate for AI agents grounded in user intent  
- Future-proof platform for geo-temporal reasoning, collaboration, and AI integration

5.
## Automated Policy-Adherent Email Routing System

### Executive Summary
The **Automated Policy-Adherent Email Routing System** is a systematic, enterprise-grade approach to processing incoming emails according to complex regulatory, confidentiality, escalation, and time-sensitive policies.  
Unlike generic LLM-based email tools or brittle rule engines, this system decomposes email routing into **explicit, auditable, multi-phase decision processes** that preserve context, prevent assumptions, and provide verifiable compliance trails.

The system is designed for **high-risk enterprise environments** where incorrect routing creates regulatory violations, legal exposure, or operational failures.

---

### Core Business Problem
Enterprises receive thousands of emails daily that must be routed according to overlapping and evolving policies involving:
- Regulatory compliance (GDPR, HIPAA, SOX, FINRA, AML)
- Escalation hierarchies (legal threats, executive issues, crisis communications)
- Confidentiality levels (personnel, proprietary, client-sensitive data)
- Time-sensitive obligations (contracts, audits, regulatory deadlines)

Current solutions fail to reliably interpret **policy combinations**, **context ambiguity**, and **edge cases**, forcing costly manual intervention.

---

### Why Existing Solutions Fail

#### Generic LLM-Based Tools
- Treat emails as single-step classification problems
- Cannot preserve decision context across multi-step evaluations
- Lack embedded knowledge of enterprise policies
- Produce un-auditable, black-box decisions
- Collapse under ambiguous or incomplete inputs

#### Traditional Rule-Based Systems
- Extremely brittle when policies change
- Require heavy manual maintenance
- Cannot interpret nuanced language
- Generate excessive false positives
- Fail silently in edge cases

---

### Real-World Impact
- **Compliance fines:** $50K–$5M per incident
- **Missed escalations:** Legal exposure, customer churn, reputational damage
- **Operational cost:** 2–4 FTEs managing routing exceptions
- **Audit failures:** No demonstrable systematic controls

---

### Design Philosophy
- **Routing decisions must be explainable**
- **Assumptions must be explicitly prevented**
- **Policies must be decomposed, not embedded**
- **Accuracy is prioritized over speed**
- **Every decision must be auditable**

---

### Core Architectural Concept

#### Incoming-Only Processing Model
Each email is evaluated independently (no reply-chain context), enabling:
- Cleaner decision boundaries
- Simplified audit trails
- Deterministic processing
- Safer failure handling

---

### Multi-Phase Decision Architecture

#### Phase 1: Sender Identification (“Who”)
Horizontal binary agents applied to every email:
- Is internal sender
- Is known customer
- Is approved vendor
- Is regulatory authority
- Is media/press
- Is unknown external

Outputs are **explicit True/False decisions** with stored reasoning.

#### Phase 2: Content & Intent Analysis (“What”)
Triggered conditionally based on Phase 1 results:
- Legal indicators
- Regulatory request language
- Personnel or HR signals
- Financial or contractual language
- Risk and urgency markers

#### Phase 3: Policy Evaluation (“Which Rules Apply”)
- Jurisdiction-specific compliance logic (GDPR vs CCPA vs internal)
- Confidentiality handling requirements
- Escalation thresholds
- Deadline and SLA activation

#### Phase 4: Risk & Routing Decision
- Routing destination(s)
- Required notifications
- Deadline tracking
- Manual review triggers (when ambiguity remains)

---

### Key Innovation: Binary, Sequential Agents
Each decision point:
- Produces a constrained True/False output
- Stores reasoning and metadata
- Writes to a persistent decision record
- Enables replay and audit reconstruction

This replaces probabilistic classification with **explicit decision trees**.

---

### Context Preservation Infrastructure
- Database-backed storage of every agent decision
- JSON-defined agent prompts and outputs
- Versioned policy logic
- Full audit trail for compliance and review

---

### Handling Ambiguity & Failure
- Explicit manual-review triggers
- Safe defaults for high-risk uncertainty
- Multi-LLM validation for critical decisions
- Disagreement detection between agents
- Clear error and retry paths

---

### Integration Scope
Designed to integrate with:
- Enterprise email systems
- CRM and customer databases
- Legal and compliance platforms
- Incident management and escalation tools
- Audit and reporting systems

---

### Industry Applicability
- **Financial Services:** FINRA, AML, complaint escalation
- **Healthcare:** HIPAA, medical urgency routing
- **Legal & Consulting:** Conflict checks, confidentiality enforcement
- **Large Enterprises:** Executive, HR, and risk communications

---

### Strategic Value
This system demonstrates how **systematic methodology outperforms ad hoc AI automation** by:
- Making policy logic explicit
- Preserving reasoning context
- Enabling compliance-grade auditability
- Scaling complexity without chaos

---

### Current Status
- Conceptual architecture defined
- Methodology validated against real enterprise failures
- Suitable for phased prototyping and controlled rollout

---

### Forward Path
Future evolution may include:
- Visual policy editors
- Agent orchestration tooling
- Compliance dashboards
- Real-time SLA monitoring
- Integration with decision frameworks (ASD / SDDF)
- Transition from framework → worksheet → application

6.
